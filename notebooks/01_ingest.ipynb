{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 2: Data Ingestion Pipeline\n",
                "\n",
                "This notebook orchestrates the loading, chunking, and structured extraction of the BRSR Report."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "# Add project root to path\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "from src.ingest import IngestionEngine\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# Initialize Engine\n",
                "engine = IngestionEngine(model_name=\"gpt-4o\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22ce6881",
            "metadata": {},
            "outputs": [],
            "source": [
                "pdf_path = \"../data/target_report.pdf\"\n",
                "\n",
                "if os.path.exists(pdf_path):\n",
                "    # 1. Load and Chunk (CalQuity Style)\n",
                "    chunks = engine.load_and_chunk(pdf_path)\n",
                "    print(f\"Loaded {len(chunks)} text chunks.\")\n",
                "    \n",
                "    # 2. Extract Structured Data (DataWeave Style)\n",
                "    # For demo, we might only send specific relevant pages to save tokens\n",
                "    # 'Principle 6' usually appears in specific sections. \n",
                "    # A naive approach is to send everything, but for costs we might filter.\n",
                "    \n",
                "    # Simple keyword filter to find relevant chunks for the Agent\n",
                "    sub_text = \"\\n\".join([c['text'] for c in chunks if \"Principle 6\" in c['text'] or \"emissions\" in c['text'].lower()])\n",
                "    \n",
                "    print(f\"Extracted Context Length: {len(sub_text)} chars\")\n",
                "    \n",
                "    # 3. Run Extraction Agent\n",
                "    data = engine.extract_principle_6(sub_text[:50000]) # Hard limit for tokens in demo\n",
                "    print(\"\\n--- Extracted Data ---\\n\")\n",
                "    print(data.model_dump_json(indent=2))\n",
                "else:\n",
                "    print(\"PDF not found. Please place 'target_report.pdf' in the data/ directory.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
